What are we doing? The TL;DR
I would like to build an application which constructs an optimized XML prompt for an LLM based on a user's natural language request. This application is one of several that I plan on uniting into one UI after they have all individually been built.

When I say optimized, what do I mean?
What I mean when I say return an "optimized XML prompt", what I mean is who better to teach us how to communicate with AI, than AI itself. Additionally, I hope that this will be an aid for people who don't really know anything about AI, LLMs, etc. For example, if a user enters a prompt which says, "Help with sorting emails, deciding which are important, and responding to them." There are several different possibilities for the output of this one. There should always be a preference for building very simple applications, if not simply a web based UI, which interfaces between the user and the LLM to accomplish their stated goal through the use of simple API calls. If needed the prompting could include the use of tools, MCP servers, etc. Security and simplicity should be the utmost importance because, again, the user will likely be unknowledgeable of security precautions and will not be able to know what to do if the prompt is not completed successfully. With that said the returned XML prompt should be as detailed and verbose as is necessary to increase the likelihood of success by the user when they use the prompt generated. To this end feel free to add any examples or guidance you think may contribute to that end.

What is the structure?
Conceptually the structure will be a tree with L1 is the user, L2 is the UI, L3 is all of these applications equally, but independently, and finally L4 is output in response to the user. * Also see the "Reference material and examples?" section for additional guidance.

APIs?
For this MVP it is perfectly acceptable to set it up for Google Gemini 2.5 Flash Exp 0417, but we will have to come back later and expand the capability for this app to use many other inference and model providers. The user API_KEY will be located in the environmental path. The security of the user's API Keys should be taken very seriously and any opportunity to protect the user's data and API Keys should be capitalized on.

What's the purpose?
When complete the larger "suite" of small application will be an aid for people unfamiliar with LLM and AI in general. So, creating a simple prompt aid, MCP server assistant, A2A assistant, etc. "suite" of applications seems like it would be helpful.

What does the UI look like?
The sibling app that I have already constructed has a "Chef/French Cafe" motif. I would like to use a different motif for each of the applications in the suite, but as of now I dont have a vision for what it could be. The concept that I am currently working with is that each on of the apps will have a unique "picturesque scene" associated with it. One application is French Cafe, another one could be a Board Room, and another a Class Room, another could be A Park in New England during The Fall, etc. This is the working concept anyway. Principally because of the audience of users who likely aren't familiar with AI or maybe even tech, I want a simple series of applications that are interesting to look at, flow from step to step well, and are difficult for the user to use incorrectly.

*Reference material and examples?
I have already finished the MCP server MVP. Please take a look at the README.md [C:\Users\AlexJ\Documents\Coding\Repos\MCP-repos\mymcp\README.md]. If you would like for me to make additional files from this repo available for you feel free to ask and I will give you access to them. I would like to mimic the construction of that application when building this one. Hopefully, this will reduce the burden of maintenance and the addition of features moving forward. If we follow the model of the MCP Server assistant application that would mean that we contrast the backend using Python, Flask for the backend service, React.js Vite for the frontend server. Using this setup is not mandatory, but encouraged. If there is a more efficient, secure, etc. setup then we can discuss switching to that framework moving forward with all applications.

Conclusion:
To reiterate this Python, Flask, React.js Vite application will take a user's natural language prompt entered into the UI, make an API call to an LLM with instructions to construct an optimized XML prompt, then returns that XML prompt to the user. For the MVP we can set it up to use Gemini 2.5 Flash Exp 0417. Although the UI may not be as refined as it will be, the UI should still be more than simply black font on white background for this MVP. Please include unit tests and edge case testing to achieve >95% test coverage.

I look forward to working with you on this project! You're always so helpful and I enjoy our time building things together. I'm in no rush, so let's take our time, develop a step-by-step plan, and then construct the application step-by-step. If we follow a step-by-step goal oriented approach I think that we will enjoy our time and create something really helpful for people. 